# Homework #2: Considering Bias in Data

## Project Goal
The goal of this project is to explore the concept of bias in data using Wikipedia articles about political figures from various countries. We will analyze the coverage and quality of Wikipedia articles about politicians to understand how bias manifests in large-scale data projects. Specifically, we will evaluate how the coverage and quality of articles differ among countries and regions by combining Wikipedia article data with country population data and using the ORES machine learning service to estimate article quality.

You can reach the author, Manya Chadha at manyac@uw.edu regarding any further questions and clarifications.

## Data Source and Description
- **Politicians Dataset**: A list of Wikipedia articles about politicians was generated by crawling the "Category:Politicians by nationality" on Wikipedia. The dataset is provided in the folder as `politicians_by_country.AUG.2024.csv`.
- **Population Dataset**: Country population data is provided in `population_by_country_AUG.2024.csv`, which was downloaded from the Population Reference Bureau's world population data sheet.
- **ORES Quality Scores**: ORES (Objective Revision Evaluation Service) is a machine learning tool used to estimate Wikipedia article quality, with quality classes ranging from Featured Article (FA) to Stub.

The data collected through the Wikimedia API for finding latest revision IDs is subject to the Wikimedia Foundation Terms of Use. Under these terms, you are allowed to reuse, adapt, and share the data, provided that proper attribution is given. In this project, the data retrieved is used for analysis purposes, adhering to the license requirements and the attribution guidelines specified.

## Analysis Steps
1. **Data Collection**
   - Use `politicians_by_country.AUG.2024.csv` to identify articles about politicians.
   - Use `population_by_country_AUG.2024.csv` to gather population data for each country and geographic region.
   - Retrieve quality predictions for each article using ORES. For this, first retrieve the latest revision ID for each article via the Wikipedia API, then query ORES for quality predictions.

2. **Data Processing**
   - Merge the politician and population datasets on country names.
   - Handle inconsistencies, such as missing matches between the two datasets, and document the process.
   - Consolidate all relevant information into a single dataset, `wp_politicians_by_country.csv`, with columns: `country`, `region`, `population`, `article_title`, `revision_id`, `article_quality`.

3. **Data Quality Checks**
   - Address inconsistencies in the politician dataset, which may include irrelevant or duplicate entries due to the Wikipedia crawl.
   - Keep regional population entries (e.g., AFRICA, OCEANIA) to conduct regional analyses.
   - Log and report articles for which ORES scores could not be retrieved and calculate the error rate.

4. **Analysis**
   - Calculate the following metrics to understand coverage and quality disparities:
     - **Total articles per capita**: The number of articles per person, by country and by region.
     - **High-quality articles per capita**: The number of high-quality articles per person, considering articles classified as FA or GA by ORES.
   - Ensure each country is assigned to the closest geographic region in the population hierarchy.

5. **Results**
   - Produce the following tables:
     1. **Top 10 countries by coverage**: Highest articles per capita.
     2. **Bottom 10 countries by coverage**: Lowest articles per capita.
     3. **Top 10 countries by high-quality coverage**: Highest high-quality articles per capita.
     4. **Bottom 10 countries by high-quality coverage**: Lowest high-quality articles per capita.
     5. **Geographic regions by total coverage**: Ranked by total articles per capita.
     6. **Geographic regions by high-quality coverage**: Ranked by high-quality articles per capita.

## Research Implications
Through this project, we aimed to understand the causes and consequences of biased data in large, complex data science projects. One key takeaway from the analysis was that **coverage and quality of articles on Wikipedia are not evenly distributed**. For instance, wealthier countries and those with more active Wikipedia contributors often have better coverage and higher-quality articles. This is likely because contributors tend to come from regions with better access to technology and education.

We also observed that the **use of folksonomic categorization** (user-defined categorization) on Wikipedia can introduce inconsistencies and biases into the dataset, which can lead to unreliable coverage. Despite OpenAI's efforts to mitigate biases, the representation of articles on political figures still varies significantly between countries and regions.

The following reflections and questions were considered:

1. **Expected Biases**: Before starting, we expected to find biases favoring countries with higher internet penetration and more Wikipedia contributors. This expectation held true, as these countries tended to have higher-quality and more comprehensive articles.

2. **Sources of Bias Discovered**: During analysis, we found biases in the training data used by ORES, which tended to reflect historical coverage imbalances, resulting in quality scores that were skewed in favor of articles from wealthier countries.

3. **Implications for Wikipedia**: These results suggest that Wikipedia's reliance on volunteer contributors may perpetuate existing global inequalities in information coverage. Countries with fewer contributors are less likely to have high-quality information available, which can affect how those regions are represented globally.

4. **Usefulness of the Data**: Despite its limitations, the dataset is still valuable for understanding representation gaps and can serve as a basis for improving coverage through targeted initiatives.

5. **Future Work**: To correct for observed biases, researchers could supplement this dataset with additional data sources or actively encourage contributions from underrepresented regions to create a more balanced representation.

## Code Documentation
- The repository contains Jupyter notebooks that document the steps for collecting, processing, and analyzing the data.
- All intermediary and supplementary data files used for analysis are included in the `data-512-homework_2` folder.
- Sample code licensed under CC-BY was reused with attribution, and API keys used in the analysis are stored securely in environment variables.

## Repository Contents
- **Notebook(s)**: The main analysis and data processing steps.
- **CSV Files**:
  - `politicians_by_country.AUG.2024.csv`: Original dataset of politicians.
  - `population_by_country_AUG.2024.csv`: Population dataset.
  - `wp_politicians_by_country.csv`: Consolidated dataset used for analysis.
- **Intermediary Files**:
  - `wp_countries-no_match.txt`: List of countries for which there were no matches.
  - Logs for articles without ORES scores.
- **Images and Tables**: Embedded in notebooks for visualization.
- **README** (this document).
- **LICENSE**: License file for the project.

## License
This project follows an MIT license, for use without restriction.
